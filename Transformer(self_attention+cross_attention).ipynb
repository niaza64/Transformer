{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbbb66a-27c9-42c3-b476-f7b9d60ca1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from accelerate) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from accelerate) (5.9.7)\n",
      "Requirement already satisfied: pyyaml in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from accelerate) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./Desktop/Llama/envs/myenv/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "!pip install accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c772b00b-b332-4a74-8be7-b993160d6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data_BGE.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e9545a-b5dd-4c74-a09b-13cf5c953e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2b6cdb-1c06-4144-9db9-c0d485fa18fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyzÆÉàâäæéêïôöüŒœάέήίαβγδεζηθικλμνξοπρςστυφχωόἀἄἆἐἑἰὀὖ᾽ῐῑ–—‘’“”﻿\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86cdcad-e2df-41a6-befc-af2e582dbbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 57, 64, 64, 67, 1, 75, 67, 70, 64, 56]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "stringtointeger = {}\n",
    "integertostring = {}\n",
    "for integer in range(len(chars)):\n",
    "  integertostring[integer] = chars[integer]\n",
    "  stringtointeger[chars[integer]] = integer\n",
    "\n",
    "def encode(s):\n",
    "    result = []\n",
    "    for c in s:\n",
    "        integer_value = stringtointeger[c]\n",
    "        result.append(integer_value)\n",
    "    return result\n",
    "\n",
    "def decode(l_integers):\n",
    "  result = []\n",
    "  for num in l_integers:\n",
    "    result.append(integertostring[num])\n",
    "  return \"\".join(result)\n",
    "\n",
    "print(encode(\"hello world\"))\n",
    "print(decode(encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa085560-7f9c-4dce-8677-ce64d1e93d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([139,  39,  41,  28,  29,  24,  26,  28,   0,  42,  44,  39,  39,  38,\n",
      "         42,  32,  37,  30,   1,  72,  60,  53,  72,   1,  43,  70,  73,  72,\n",
      "         60,   1,  61,  71,   1,  53,   1,  75,  67,  65,  53,  66, 134,  75,\n",
      "         60,  53,  72,   1,  72,  60,  57,  66,  23,   1,  32,  71,   1,  72,\n",
      "         60,  57,  70,  57,   1,  66,  67,  72,   1,  59,  70,  67,  73,  66,\n",
      "         56,   1,  58,  67,  70,   1,  71,  73,  71,  68,  57,  55,  72,  61,\n",
      "         66,  59,   1,  72,  60,  53,  72,   1,  53,  64,  64,   1,  68,  60,\n",
      "         61,  64,  67,  71,  67,  68,  60,  57,  70,  71,   7,   1,  61,  66,\n",
      "          1,  71,  67,   1,  58,  53,  70,   1,  53,  71,   1,  72,  60,  57,\n",
      "         77,   1,  60,  53,  74,  57,   1,  54,  57,  57,  66,   1,  56,  67,\n",
      "         59,  65,  53,  72,  61,  71,  72,  71,   7,   1,  60,  53,  74,  57,\n",
      "          1,  58,  53,  61,  64,  57,  56,   1,  72,  67,   1,  73,  66,  56,\n",
      "         57,  70,  71,  72,  53,  66,  56,   1,  75,  67,  65,  57,  66, 134,\n",
      "         72,  60,  53,  72,   1,  72,  60,  57,   1,  72,  57,  70,  70,  61,\n",
      "         54,  64,  57,   1,  71,  57,  70,  61,  67,  73,  71,  66,  57,  71,\n",
      "         71,   1,  53,  66,  56,   1,  55,  64,  73,  65,  71,  77,   1,  61,\n",
      "         65,  68,  67,  70,  72,  73,  66,  61,  72,  77,   1,  75,  61,  72,\n",
      "         60,   1,  75,  60,  61,  55,  60,   1,  72,  60,  57,  77,   1,  60,\n",
      "         53,  74,  57,   1,  73,  71,  73,  53,  64,  64,  77,   1,  68,  53,\n",
      "         61,  56,   1,  72,  60,  57,  61,  70,   1,  53,  56,  56,  70,  57,\n",
      "         71,  71,  57,  71,   1,  72,  67,   1,  43,  70,  73,  72,  60,   7,\n",
      "          1,  60,  53,  74,  57,   1,  54,  57,  57,  66,   1,  73,  66,  71,\n",
      "         63,  61,  64,  64,  57,  56,   1,  53,  66,  56,   1,  73,  66,  71,\n",
      "         57,  57,  65,  64,  77,   1,  65,  57,  72,  60,  67,  56,  71,   1,\n",
      "         58,  67,  70,   1,  75,  61,  66,  66,  61,  66,  59,   1,  53,   1,\n",
      "         75,  67,  65,  53,  66,  23,   1,  26,  57,  70,  72,  53,  61,  66,\n",
      "         64,  77,   1,  71,  60,  57,   1,  60,  53,  71,   1,  66,  57,  74,\n",
      "         57,  70,   1,  53,  64,  64,  67,  75,  57,  56,   1,  60,  57,  70,\n",
      "         71,  57,  64,  58,   1,  72,  67,   1,  54,  57,   1,  75,  67,  66,\n",
      "         21,   1,  53,  66,  56,   1,  53,  72,   1,  68,  70,  57,  71,  57,\n",
      "         66,  72,   1,  57,  74,  57,  70,  77,   1,  63,  61,  66,  56,   1,\n",
      "         67,  58,   1,  56,  67,  59,  65,  53,   1,  71,  72,  53,  66,  56,\n",
      "         71,   1,  75,  61,  72,  60,   1,  71,  53,  56,   1,  53,  66,  56,\n",
      "          1,  56,  61,  71,  55,  67,  73,  70,  53,  59,  57,  56,   1,  65,\n",
      "         61,  57,  66, 134,  32,  29,   7,   1,  61,  66,  56,  57,  57,  56,\n",
      "          7,   1,  61,  72,   1,  71,  72,  53,  66,  56,  71,   1,  53,  72,\n",
      "          1,  53,  64,  64,   2,   1,  29,  67,  70,   1,  72,  60,  57,  70,\n",
      "         57,   1,  53,  70,  57,   1,  71,  55,  67,  58,  58,  57,  70,  71,\n",
      "          1,  75,  60,  67,   1,  65,  53,  61,  66,  72,  53,  61,  66,   1,\n",
      "         72,  60,  53,  72,   1,  61,  72,   1,  60,  53,  71,   1,  58,  53,\n",
      "         64,  64,  57,  66,   7,   1,  72,  60,  53,  72,   1,  53,  64,  64,\n",
      "          1,  56,  67,  59,  65,  53,   1,  64,  61,  57,  71,   1,  67,  66,\n",
      "          1,  72,  60,  57,   1,  59,  70,  67,  73,  66,  56, 134,  66,  53,\n",
      "         77,   1,  65,  67,  70,  57,   7,   1,  72,  60,  53,  72,   1,  61,\n",
      "         72,   1,  61,  71,   1,  53,  72,   1,  61,  72,  71,   1,  64,  53,\n",
      "         71,  72,   1,  59,  53,  71,  68,   9,   1,  25,  73,  72,   1,  72,\n",
      "         67,   1,  71,  68,  57,  53,  63,   1,  71,  57,  70,  61,  67,  73,\n",
      "         71,  64,  77,   7,   1,  72,  60,  57,  70,  57,   1,  53,  70,  57,\n",
      "          1,  59,  67,  67,  56,   1,  59,  70,  67,  73,  66,  56,  71,   1,\n",
      "         58,  67,  70,   1,  60,  67,  68,  61,  66,  59,   1,  72,  60,  53,\n",
      "         72,   1,  53,  64,  64,   1,  56,  67,  59,  65,  53,  72,  61,  78,\n",
      "         61,  66,  59,   1,  61,  66,   1,  68,  60,  61,  64,  67,  71,  67,\n",
      "         68,  60,  77,   7,   1,  75,  60,  53,  72,  57,  74,  57,  70,   1,\n",
      "         71,  67,  64,  57,  65,  66,   7,   1,  75,  60,  53,  72,  57,  74,\n",
      "         57,  70,   1,  55,  67,  66,  55,  64,  73,  71,  61,  74,  57,   1,\n",
      "         53,  66,  56,   1,  56,  57,  55,  61,  56,  57,  56,   1,  53,  61,\n",
      "         70,  71,   1,  61,  72,   1,  60,  53,  71,   1,  53,  71,  71,  73,\n",
      "         65,  57,  56,   7,   1,  65,  53,  77,   1,  60,  53,  74,  57,   1,\n",
      "         54,  57,  57,  66,   1,  67,  66,  64,  77,   1,  53,   1,  66,  67,\n",
      "         54,  64,  57,   1,  68,  73,  57,  70,  61,  64,  61,  71,  65,   1,\n",
      "         53,  66,  56,   1,  72,  77,  70,  67,  66,  61,  71,  65,  21,   1,\n",
      "         53,  66,  56,   1,  68,  70,  67,  54,  53,  54,  64,  77,   1,  72,\n",
      "         60,  57,   1,  72,  61,  65,  57,   1,  61,  71,   1,  53,  72,   1,\n",
      "         60,  53,  66,  56,   1,  75,  60,  57,  66,   1,  61,  72,   1,  75,\n",
      "         61,  64,  64,   1,  54,  57,   1,  67,  66,  55,  57,   1,  53,  66,\n",
      "         56,   1,  53,  59,  53,  61,  66,   1,  73,  66,  56,  57,  70,  71,\n",
      "         72,  67,  67,  56,   1,  46,  31,  24,  43,   1,  60,  53,  71,   1,\n",
      "         53,  55,  72,  73,  53,  64,  64,  77,   1,  71,  73,  58,  58,  61,\n",
      "         55,  57,  56,   1,  58,  67,  70,   1,  72,  60,  57,   1,  54,  53,\n",
      "         71,  61,  71,   1,  67,  58,   1,  71,  73,  55,  60,   1,  61,  65,\n",
      "         68,  67,  71,  61,  66,  59,   1,  53,  66,  56,   1,  53,  54,  71,\n",
      "         67,  64,  73,  72,  57,   1])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1829d68-1471-46be-bfba-0628a0a6ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) #Use 90 percent for training and the 10 percent data for validation\n",
    "training_data = data[:n]\n",
    "validation_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218fe390-4a91-4b7b-9e76-a10845a8b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([139,  39,  41,  28,  29,  24,  26,  28,   0])\n"
     ]
    }
   ],
   "source": [
    "context_size = 8\n",
    "print(training_data[:context_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bc5a6d-86f7-48c3-9021-4407879dd32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([139]) ouput 39\n",
      "input tensor([139,  39]) ouput 41\n",
      "input tensor([139,  39,  41]) ouput 28\n",
      "input tensor([139,  39,  41,  28]) ouput 29\n",
      "input tensor([139,  39,  41,  28,  29]) ouput 24\n",
      "input tensor([139,  39,  41,  28,  29,  24]) ouput 26\n",
      "input tensor([139,  39,  41,  28,  29,  24,  26]) ouput 28\n",
      "input tensor([139,  39,  41,  28,  29,  24,  26,  28]) ouput 0\n"
     ]
    }
   ],
   "source": [
    "input_data = training_data[:context_size]\n",
    "expected_output = training_data[1:context_size+1]\n",
    "for i in range(context_size):\n",
    "  context = input_data[:i+1]\n",
    "  target = expected_output[i]\n",
    "  print(f\"input {context} ouput {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf75121-a7a4-4a1b-bfea-2824eaec01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "context_size = 8\n",
    "def get_batch(data_type):\n",
    "    data = training_data if data_type == \"training_data\" else validation_data\n",
    "    index_for_batches = torch.randint(len(data)-context_size, (batch_size,))\n",
    "    print(index_for_batches)\n",
    "    x = torch.stack([data[index:index+context_size] for index in index_for_batches])\n",
    "    y = torch.stack([data[index+1:index+context_size+1] for index in index_for_batches])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f8ee41-d3d4-4f3d-8dc7-b6e7b3801f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 57979, 140986,  79898,  48462,   6370,  49490])\n"
     ]
    }
   ],
   "source": [
    "input, output = get_batch(\"traning_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb817ff-bcf5-487d-ae1b-440ba435da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([6, 8]) output torch.Size([6, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"input\", input.shape, \"output\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d40bd85-f143-424f-bd66-abedd4ac3aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66)\n",
      "input_to_model_context tensor([53]) expected_output tensor(66)\n",
      "tensor(56)\n",
      "input_to_model_context tensor([53, 66]) expected_output tensor(56)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([53, 66, 56]) expected_output tensor(1)\n",
      "tensor(67)\n",
      "input_to_model_context tensor([53, 66, 56,  1]) expected_output tensor(67)\n",
      "tensor(58)\n",
      "input_to_model_context tensor([53, 66, 56,  1, 67]) expected_output tensor(58)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([53, 66, 56,  1, 67, 58]) expected_output tensor(1)\n",
      "tensor(37)\n",
      "input_to_model_context tensor([53, 66, 56,  1, 67, 58,  1]) expected_output tensor(37)\n",
      "tensor(53)\n",
      "input_to_model_context tensor([53, 66, 56,  1, 67, 58,  1, 37]) expected_output tensor(53)\n",
      "tensor(72)\n",
      "input_to_model_context tensor([55]) expected_output tensor(72)\n",
      "tensor(53)\n",
      "input_to_model_context tensor([55, 72]) expected_output tensor(53)\n",
      "tensor(72)\n",
      "input_to_model_context tensor([55, 72, 53]) expected_output tensor(72)\n",
      "tensor(67)\n",
      "input_to_model_context tensor([55, 72, 53, 72]) expected_output tensor(67)\n",
      "tensor(70)\n",
      "input_to_model_context tensor([55, 72, 53, 72, 67]) expected_output tensor(70)\n",
      "tensor(71)\n",
      "input_to_model_context tensor([55, 72, 53, 72, 67, 70]) expected_output tensor(71)\n",
      "tensor(7)\n",
      "input_to_model_context tensor([55, 72, 53, 72, 67, 70, 71]) expected_output tensor(7)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([55, 72, 53, 72, 67, 70, 71,  7]) expected_output tensor(1)\n",
      "tensor(67)\n",
      "input_to_model_context tensor([72]) expected_output tensor(67)\n",
      "tensor(70)\n",
      "input_to_model_context tensor([72, 67]) expected_output tensor(70)\n",
      "tensor(61)\n",
      "input_to_model_context tensor([72, 67, 70]) expected_output tensor(61)\n",
      "tensor(55)\n",
      "input_to_model_context tensor([72, 67, 70, 61]) expected_output tensor(55)\n",
      "tensor(53)\n",
      "input_to_model_context tensor([72, 67, 70, 61, 55]) expected_output tensor(53)\n",
      "tensor(64)\n",
      "input_to_model_context tensor([72, 67, 70, 61, 55, 53]) expected_output tensor(64)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([72, 67, 70, 61, 55, 53, 64]) expected_output tensor(1)\n",
      "tensor(68)\n",
      "input_to_model_context tensor([72, 67, 70, 61, 55, 53, 64,  1]) expected_output tensor(68)\n",
      "tensor(70)\n",
      "input_to_model_context tensor([73]) expected_output tensor(70)\n",
      "tensor(57)\n",
      "input_to_model_context tensor([73, 70]) expected_output tensor(57)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([73, 70, 57]) expected_output tensor(1)\n",
      "tensor(67)\n",
      "input_to_model_context tensor([73, 70, 57,  1]) expected_output tensor(67)\n",
      "tensor(58)\n",
      "input_to_model_context tensor([73, 70, 57,  1, 67]) expected_output tensor(58)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([73, 70, 57,  1, 67, 58]) expected_output tensor(1)\n",
      "tensor(72)\n",
      "input_to_model_context tensor([73, 70, 57,  1, 67, 58,  1]) expected_output tensor(72)\n",
      "tensor(60)\n",
      "input_to_model_context tensor([73, 70, 57,  1, 67, 58,  1, 72]) expected_output tensor(60)\n",
      "tensor(70)\n",
      "input_to_model_context tensor([57]) expected_output tensor(70)\n",
      "tensor(66)\n",
      "input_to_model_context tensor([57, 70]) expected_output tensor(66)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([57, 70, 66]) expected_output tensor(1)\n",
      "tensor(71)\n",
      "input_to_model_context tensor([57, 70, 66,  1]) expected_output tensor(71)\n",
      "tensor(68)\n",
      "input_to_model_context tensor([57, 70, 66,  1, 71]) expected_output tensor(68)\n",
      "tensor(61)\n",
      "input_to_model_context tensor([57, 70, 66,  1, 71, 68]) expected_output tensor(61)\n",
      "tensor(70)\n",
      "input_to_model_context tensor([57, 70, 66,  1, 71, 68, 61]) expected_output tensor(70)\n",
      "tensor(61)\n",
      "input_to_model_context tensor([57, 70, 66,  1, 71, 68, 61, 70]) expected_output tensor(61)\n",
      "tensor(43)\n",
      "input_to_model_context tensor([1]) expected_output tensor(43)\n",
      "tensor(60)\n",
      "input_to_model_context tensor([ 1, 43]) expected_output tensor(60)\n",
      "tensor(57)\n",
      "input_to_model_context tensor([ 1, 43, 60]) expected_output tensor(57)\n",
      "tensor(1)\n",
      "input_to_model_context tensor([ 1, 43, 60, 57]) expected_output tensor(1)\n",
      "tensor(71)\n",
      "input_to_model_context tensor([ 1, 43, 60, 57,  1]) expected_output tensor(71)\n",
      "tensor(67)\n",
      "input_to_model_context tensor([ 1, 43, 60, 57,  1, 71]) expected_output tensor(67)\n",
      "tensor(66)\n",
      "input_to_model_context tensor([ 1, 43, 60, 57,  1, 71, 67]) expected_output tensor(66)\n",
      "tensor(59)\n",
      "input_to_model_context tensor([ 1, 43, 60, 57,  1, 71, 67, 66]) expected_output tensor(59)\n"
     ]
    }
   ],
   "source": [
    "for row in range(batch_size): #to acesss the each tensor at each row\n",
    "    for col in range(context_size): #to access each tokenize value at each column\n",
    "        input_to_model_context =  input[row, :col+1] #each row upto the col+1 as col+1 isnt included\n",
    "        print(output[row,col])\n",
    "        expect_y = output[row,col] # specfic word not a list\n",
    "        print(\"input_to_model_context\", input_to_model_context, \"expected_output\", expect_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ffc6c7b-b4de-4e66-8c5a-71c16830e8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "Batch, Token, Channel = 4,8,2\n",
    "x = torch.randn(Batch, Token, Channel)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d52e4d-38c8-40d9-a5e8-c9d06712e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbagofwords = torch.zeros((Batch, Token, Channel)) #here we want to have some form of communication between the token.in this case we would take average all the number before it\"\"\"\n",
    "\n",
    "for b in range(Batch):\n",
    "    for t in range(Token):\n",
    "        xprev = x[b, :t+1]   #in the b row upto t, including t\n",
    "        xbagofwords[b,t] = torch.mean(xprev,0) #here at the position t in some random batch b we have average all the previous numbers. Like attention.\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4fbcb5-9996-4468-b190-5adb1154cd9d",
   "metadata": {},
   "source": [
    "if you have a tensor x with the shape (1, 3, 2), the data might look something like this:\n",
    "\n",
    "x = torch.tensor([[[1, 2], [3, 4], [5, 6]]])\n",
    "\n",
    "You have 1 batch (Batch = 1).\n",
    "Each batch contains 3 tokens (Token = 3).\n",
    "Each token is represented by a 2-dimensional vector (or 2 features per token, Channel = 2).\n",
    "In this tensor:\n",
    "\n",
    "The first dimension (Batch) has only one element.\n",
    "The second dimension (Token) represents the three tokens.\n",
    "The third dimension (Channel) represents the two features (or channels) for each token.\n",
    "When you refer to [1, 3, 5] and [2, 4, 6], you're essentially talking about the two features (channels) across the three tokens. Here's how they are distributed:\n",
    "\n",
    "The first feature (channel) across the three tokens is [1, 3, 5].\n",
    "The second feature (channel) across the three tokens is [2, 4, 6].\n",
    "\n",
    "For each token t, you're selecting all tokens up to and including the current one (x[b, :t+1]), and then computing the mean along the first dimension (Token).\n",
    "This mean is calculated separately for each feature (channel). So, for the first token, the mean would just be the features of the first token itself. For the second token, it would be the mean of the features of the first and second tokens, and so on.\n",
    "So, in the context of calculating the mean:\n",
    "\n",
    "When t = 0, xprev is [[1, 2]], and the mean is [1, 2] (since there's only one token to consider).\n",
    "When t = 1, xprev is [[1, 2], [3, 4]], and the mean for each feature would be:\n",
    "First feature: mean of [1, 3] -> 2\n",
    "Second feature: mean of [2, 4] -> 3\n",
    "The result for t = 1 would be [2, 3], and so on for larger t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5018e8e6-efe8-41ba-b4dc-04f5e22cdcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3333,  0.8926],\n",
      "        [-1.0479,  0.3544],\n",
      "        [-0.9779, -0.2347],\n",
      "        [-0.9516, -0.1231],\n",
      "        [-0.4728, -0.0203],\n",
      "        [-0.2053,  0.0659],\n",
      "        [-0.2575,  0.1247],\n",
      "        [-0.0109,  0.1433]])\n"
     ]
    }
   ],
   "source": [
    "print(xbagofwords[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a7c3e-b5c3-4ae8-be0e-ecf517a87bac",
   "metadata": {},
   "source": [
    "The method of allowing each token to access information from others can be extremely inefficient, particularly when considering the O(n^2) complexity involved in the multiplication process. Let's explore how we can optimize this using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8a8d249-747a-497f-bf57-dbfeda34af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_2 tensor([[1., 0.],\n",
      "        [5., 5.],\n",
      "        [7., 2.]]) simple_matrix tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) c tensor([[13.,  7.],\n",
      "        [13.,  7.],\n",
      "        [13.,  7.]])\n"
     ]
    }
   ],
   "source": [
    "simple_matrix = torch.ones(3,3)\n",
    "matrix_2 = torch.randint(0,10,(3,2)).float() \n",
    "c = simple_matrix @ matrix_2\n",
    "print(\"matrix_2\",matrix_2, \"simple_matrix\", simple_matrix, \"c\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910181e-8be6-408b-8cb8-4b430b88988d",
   "metadata": {},
   "source": [
    "now what if we define simple_matrix as identity matrix as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25b68761-f236-4898-a592-b87c7149ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_matrix = torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0bbd278-4e63-4442-bf7a-630ea9d09ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(simple_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cd0cadd-3dba-4d24-8d64-89de09949a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.,  7.],\n",
      "        [12., 11.],\n",
      "        [13., 16.]])\n"
     ]
    }
   ],
   "source": [
    "simple_matrix = torch.tril(torch.ones(3,3))\n",
    "matrix_2 = torch.randint(0,10,(3,2)).float() \n",
    "c = simple_matrix @ matrix_2\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754ccdb-afea-49c5-98ef-2064041a68cf",
   "metadata": {},
   "source": [
    "This form of skew identity matrix will help us in accumulating sum. but we need the mean not the averge not the sum. Lets see how we can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d1b533a-de8b-4a2a-990d-1a3de0852a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 9.],\n",
      "        [3., 2.],\n",
      "        [1., 8.]]) tensor([[4.0000, 9.0000],\n",
      "        [3.5000, 5.5000],\n",
      "        [2.6667, 6.3333]])\n"
     ]
    }
   ],
   "source": [
    "simple_matrix = torch.tril(torch.ones(3, 3))\n",
    "simple_matrix = simple_matrix / torch.sum(simple_matrix, 1, keepdim=True)\n",
    "matrix_2 = torch.randint(0,10,(3,2)).float() \n",
    "c = simple_matrix @ matrix_2\n",
    "print(matrix_2, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9b08d-3aa0-4641-9451-66b5ecab1a05",
   "metadata": {},
   "source": [
    "let's get back to our orginal example now\n",
    "xbagofwords = torch.zeros((Batch, Token, Channel)) #here we want to have some form of communication between the token.in this case we would take average all the number before it\"\"\"\n",
    "\n",
    "for b in range(Batch):\n",
    "    for t in range(Token):\n",
    "        xprev = x[b, :t+1]   #in the b row upto t, including t\n",
    "        xbagofwords[b,t] = torch.mean(xprev,0) #here at the position t in some random batch b we have average all the previous numbers. Like attention.\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31e36a3d-6250-41d6-9635-8dc0f8ced6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_matrix = torch.tril(torch.ones(Token,Token))\n",
    "identity_matrix = identity_matrix / torch.sum(identity_matrix, 1, keepdim=True)\n",
    "xbagofwords_e = identity_matrix @ x # (B, T, T) @ (B, T, C)\n",
    "torch.allclose(xbagofwords, xbagofwords_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34bb896a-55c5-4dba-b052-2d12717de1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(Token,Token))\n",
    "print(tril)\n",
    "identity_matrix = torch.zeros((Token,Token))\n",
    "print(identity_matrix)\n",
    "\n",
    "identity_matrix = identity_matrix.masked_fill(tril == 0, float('-inf'))\n",
    "#this make sure that no forward communication happens between the tokens\n",
    "print(identity_matrix)\n",
    "identity_matrix = F.softmax(identity_matrix, dim=-1) # exponentiate and divide by the sum of exponent will give us probablility\n",
    "print(identity_matrix)\n",
    "xbagofwords_3 = identity_matrix @ x\n",
    "torch.allclose(xbagofwords, xbagofwords_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164b196-a2e3-4419-a5e3-b4d50d055560",
   "metadata": {},
   "source": [
    "Let's move on to the crux of \"Attention is all you need\" paper. i.e self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9ec84d0-53ac-4045-bdda-2608f3f9fd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Batch, Tokens, Channels = 4, 8, 32\n",
    "x = torch.randn(Batch,Token,Channels)\n",
    "tril = torch.tril(torch.ones(Tokens, Tokens)) \n",
    "identity_matrix = torch.zeros((Token,Token))\n",
    "\n",
    "\n",
    "identity_matrix = identity_matrix.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "identity_matrix = F.softmax(identity_matrix, dim=-1) # exponentiate and divide by the sum of exponent will give us probablility\n",
    "\n",
    "output = identity_matrix @ x\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e86178-8cc2-48f3-904f-b2a5f7c8d2c3",
   "metadata": {},
   "source": [
    "Right now, we're essentially averaging all the last tokens in each batch at every point. But remember, there's no forward communication. This is thanks to how we've set up the '-inf' in the identity_matrix. However, based on the context (the data), this averaging shouldn't just be uniform. Instead, it should be weighted according to the data.\n",
    "\n",
    "Let's dive deeper into how the key, query, and value really work at the core. Picture this: every token in each batch emits two things – a query and a key. Think of a query as asking, 'What am I looking for?' and a key as saying, 'Here’s what I represent.' So, each token broadcasts its query to all preceding tokens (not the ones ahead, remember the infinity setup) in the same batch, essentially saying, 'I'm searching for this info.' This call is answered by the last tokens through their keys. We use the dot product as a measure of how similar the query and the key are. A larger dot product value indicates greater similarity. This similarity score gets stored in the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56d27b38-cf2d-4afa-859b-4e48eda3d758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Batch, Tokens, Channels = 4, 8, 32\n",
    "\n",
    "x = torch.randn(Batch,Token,Channels)\n",
    "\n",
    "#single head self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(Channels, head_size, bias=False)\n",
    "query = nn.Linear(Channels, head_size, bias=False)\n",
    "value = nn.Linear(Channels, head_size, bias=False)\n",
    "key = key(x)\n",
    "query = query(x)\n",
    "identity_matrix = query @ key.transpose(-2, -1) #(B,T,16) @ (B,16,T) ----> (B, T, T) for each Batch we have T, T matrix\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(Tokens, Tokens)) \n",
    "identity_matrix = torch.zeros((Token,Token))\n",
    "\n",
    "\n",
    "identity_matrix = identity_matrix.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "identity_matrix = F.softmax(identity_matrix, dim=-1) # exponentiate and divide by the sum of exponent will give us probablility\n",
    "v = value(x)\n",
    "output = identity_matrix @ v\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c6d38-c2ee-44b0-bd8a-63656431dfcf",
   "metadata": {},
   "source": [
    "In the case of cross-attention, as utilized in the encoder-decoder architecture of Transformer models, it is necessary to omit the\n",
    "use of float('-inf'). This adjustment is important because, in cross-attention, tokens are allowed to communicate with each other, \n",
    "which is a key aspect of how the encoder and decoder interact. This approach differs from the self-attention mechanism in the encoder, \n",
    "where the use of float('-inf') is applied to prevent forward-looking information flow. The original Transformer paper, which introduced \n",
    "the encoder-decoder architecture, implements this strategy to facilitate effective communication between tokens across the encoder and \n",
    "decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62833c9f-c0b1-4d8f-866f-fbca1e7bf0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
